{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cell"
      ],
      "metadata": {
        "id": "6CcI7p3rxKYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN ME!!!\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "balanced_file_path = '/content/drive/My Drive/NLP Final Project/balanced_df.csv'\n",
        "tech_file_path = '/content/drive/My Drive/NLP Final Project/tech_data.csv'\n",
        "\n",
        "\n",
        "try:\n",
        "    balanced_df = pd.read_csv(balanced_file_path)\n",
        "    tech_data = pd.read_csv(tech_file_path)\n",
        "    print(\"DataFrame loaded successfully from Google Drive.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Csv not found in Google Drive.\")"
      ],
      "metadata": {
        "id": "Z7CoDpUjukAI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BoW with TF-IDF ##"
      ],
      "metadata": {
        "id": "6IFyidfzDqP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "VBruucIFDv4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfidf_embeddings(train_data, test_data):\n",
        "  # Create BOW\n",
        "  vectorizer = CountVectorizer()\n",
        "  bow = vectorizer.fit_transform(train_data)\n",
        "\n",
        "  # TF-IDF weighting\n",
        "  tfidf_transformer = TfidfTransformer()\n",
        "  tfidf = tfidf_transformer.fit_transform(bow)\n",
        "\n",
        "  # Get TF-IDF embeddings for test data\n",
        "  test_bow = vectorizer.transform(test_data)\n",
        "  test_tfidf = tfidf_transformer.transform(test_bow)\n",
        "  return test_tfidf"
      ],
      "metadata": {
        "id": "Ef2edIvkFc4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the P@1 accuracy\n",
        "def p_at_1_accuracy(cosine_distances_matrix, keyword_rows):\n",
        "  best_matches = np.argmin(cosine_distances_matrix, axis=1)\n",
        "  correct_indices = np.arange(len(keyword_rows))\n",
        "  correct_matches = (best_matches == correct_indices)\n",
        "  accuracy = np.mean(correct_matches)\n",
        "  print(f\"Top-1 Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "mnrhsBVNGA3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def p_at_1_accuracy_bow(cosine_distances_matrix, duplicates_df):\n",
        "  predicted_indices = np.argmin(cosine_distances_matrix, axis=1)\n",
        "  correct_predictions = 0\n",
        "  for i, pred_idx in enumerate(predicted_indices):\n",
        "    if duplicates_df.index[i] == pred_idx:\n",
        "      correct_predictions += 1\n",
        "  accuracy = correct_predictions / len(duplicates_df)\n",
        "  print(f\"Top-1 Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "l-T4zCNY4TQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the P@3 accuracy\n",
        "def p_at_3_accuracy(cosine_distances_matrix, keyword_rows):\n",
        "  top_3_matches = np.argsort(cosine_distances_matrix, axis=1)[:,:3]\n",
        "  correct_matches = np.array([i in top_3_matches[i] for i in range(len(keyword_rows))])\n",
        "  top_3_accuracy = np.mean(correct_matches)\n",
        "  print(f\"Top-3 Accuracy: {top_3_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "eNSTOkJVI9Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def p_at_3_accuracy_bow(cosine_distances_matrix, duplicates_df):\n",
        "  correct_predictions = 0\n",
        "  for i in range(len(duplicates_df)):\n",
        "    top_3_matches = np.argsort(cosine_distances_matrix[i])[:3]\n",
        "    if duplicates_df.index[i] in top_3_matches:\n",
        "      correct_predictions += 1\n",
        "  top_3_accuracy = correct_predictions / len(duplicates_df)\n",
        "  print(f\"Top-3 Accuracy: {top_3_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "trglnvEI5i8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the MRR\n",
        "def mrr(cosine_distances_matrix, keyword_rows):\n",
        "  correct_ranks = []\n",
        "  for i in range(len(keyword_rows)):\n",
        "    sorted_indices = np.argsort(cosine_distances_matrix[i])\n",
        "    rank = np.where(sorted_indices == i)\n",
        "    correct_ranks.append(rank[0][0] + 1)\n",
        "  mrr = np.mean([1 / rank for rank in correct_ranks])\n",
        "  print(f\"MRR: {mrr:.4f}\")"
      ],
      "metadata": {
        "id": "YB213uFrO_kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mrr_bow(cosine_distances_matrix, duplicates_df):\n",
        "  correct_ranks = []\n",
        "  for i in range(len(duplicates_df)):\n",
        "    sorted_indices = np.argsort(cosine_distances_matrix[i])\n",
        "    if duplicates_df.index[i] in sorted_indices:\n",
        "      rank = np.where(sorted_indices == duplicates_df.index[i])\n",
        "      correct_ranks.append(1 / (rank[0][0] + 1))\n",
        "    else:\n",
        "      correct_ranks.append(0)\n",
        "  mrr = np.mean(correct_ranks)\n",
        "  print(f\"MRR: {mrr:.4f}\")"
      ],
      "metadata": {
        "id": "dbxBSOjS6TET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting accuracy with tau threshold\n",
        "def tau_accuracy(cosine_distances_matrix, balanced_df):\n",
        "  threshold = 0.8\n",
        "  cosine_similarity_matrix = 1 - cosine_distances_matrix\n",
        "\n",
        "  row_accuracies = []\n",
        "  for idx, row in balanced_df.iterrows():\n",
        "    is_duplicate = row[\"is_duplicate\"]\n",
        "    similarity = cosine_similarity_matrix[idx, idx]\n",
        "\n",
        "    if is_duplicate == 1:\n",
        "      row_accuracies.append(similarity >= threshold)\n",
        "    else:\n",
        "      row_accuracies.append(similarity < threshold)\n",
        "\n",
        "  row_wise_accuracy = np.mean(row_accuracies)\n",
        "  print(f\"Overall Accuracy with threshold 0.8: {row_wise_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "qCwQm37u11om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the tech dataset"
      ],
      "metadata": {
        "id": "pwNVguEYnFNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(tech_data, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "9Z_RE-8M2Ozf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions = train_df[\"question1\"].tolist() + train_df[\"question2\"].tolist()\n",
        "test_questions = test_df[\"question1\"].tolist() + test_df[\"question2\"].tolist()"
      ],
      "metadata": {
        "id": "LC1jy5baFu-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_embeddings = get_tfidf_embeddings(train_questions, test_questions)\n",
        "\n",
        "question1_embeddings = test_embeddings[:len(test_df)]\n",
        "question2_embeddings = test_embeddings[len(test_df):]\n",
        "\n",
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "FWgnLtX3FwaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "RSeGRzVR33a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = test_df[test_df[\"is_duplicate\"] == 1]\n",
        "duplicate_indices = duplicates.index.tolist()\n",
        "cosine_distances_duplicates = cosine_distances_matrix[duplicate_indices, :]\n",
        "\n",
        "p_at_1_accuracy_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "NmHhJXDcxcLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_at_3_accuracy_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "PcTLGy_MeJBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "kVyIQWWceRhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_accuracy(cosine_distances_matrix, test_df)"
      ],
      "metadata": {
        "id": "7KB-_wNmlCN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the general dataset"
      ],
      "metadata": {
        "id": "gzz_s_cShgN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(balanced_df, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "dOYkYJl56uTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions = train_df[\"question1\"].tolist() + train_df[\"question2\"].tolist()\n",
        "test_questions = test_df[\"question1\"].tolist() + test_df[\"question2\"].tolist()"
      ],
      "metadata": {
        "id": "IE44jBPg6wBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_embeddings = get_tfidf_embeddings(train_questions, test_questions)\n",
        "\n",
        "question1_embeddings = test_embeddings[:len(test_df)]\n",
        "question2_embeddings = test_embeddings[len(test_df):]\n",
        "\n",
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "JXga9vkS6082"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "orYqRKZ0pBwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = test_df[test_df[\"is_duplicate\"] == 1]\n",
        "duplicate_indices = duplicates.index.tolist()\n",
        "cosine_distances_duplicates = cosine_distances_matrix[duplicate_indices, :]\n",
        "\n",
        "p_at_1_accuracy_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "uh5bKVngea9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_at_3_accuracy_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "NYp8TqKxpwfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "fgJcAZyoqRG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_accuracy(cosine_distances_matrix, test_df)"
      ],
      "metadata": {
        "id": "EkXZ4WNkuToD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Trained Word2Vec ##"
      ],
      "metadata": {
        "id": "mI-FyAZMKbJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.models\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/NLP Final Project/GoogleNews-vectors-negative300.bin\", binary=True)"
      ],
      "metadata": {
        "id": "uN0b55gFL0pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the tech dataset"
      ],
      "metadata": {
        "id": "CxvhxRZEBbK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_questions = tech_data[\"question1\"].tolist() + tech_data[\"question2\"].tolist()"
      ],
      "metadata": {
        "id": "Fxyqh8TSMTFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(all_questions)"
      ],
      "metadata": {
        "id": "ucoG53o2ht4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weighted_question_embedding(question, tfidf_vectorizer, tfidf, i, word2vec):\n",
        "  vocab_questions = tfidf_vectorizer.vocabulary_\n",
        "  question_words = question.split()\n",
        "  word_embeddings = []\n",
        "  weights = []\n",
        "\n",
        "  for word in question_words:\n",
        "    if word in vocab_questions and word in word2vec:\n",
        "      word_index = vocab_questions[word]\n",
        "      word_weight = tfidf[i, word_index]\n",
        "      word_embedding = word2vec[word]\n",
        "      word_embeddings.append(word_embedding * word_weight)\n",
        "      weights.append(word_weight)\n",
        "\n",
        "  if word_embeddings:\n",
        "    question_embedding = np.sum(word_embeddings, axis=0) / np.sum(weights)\n",
        "\n",
        "  else:\n",
        "    print(\"No words found\")\n",
        "    question_embedding = np.zeros(word2vec.vector_size)\n",
        "\n",
        "  return question_embedding"
      ],
      "metadata": {
        "id": "ydFo4KHqUBRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1_embeddings = np.array([get_weighted_question_embedding(q, tfidf_vectorizer, tfidf, i, model)\n",
        "                                for i, q in enumerate(tech_data[\"question1\"])])"
      ],
      "metadata": {
        "id": "_ItCQFEtUSy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question2_embeddings = np.array([get_weighted_question_embedding(q, tfidf_vectorizer, tfidf, i + len(tech_data), model)\n",
        "                                for i, q in enumerate(tech_data[\"question2\"])])"
      ],
      "metadata": {
        "id": "pvwXz8ESUVEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "hLEQrFZfUdbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = tech_data[tech_data[\"is_duplicate\"] == 1]\n",
        "duplicate_indices = duplicates.index.tolist()\n",
        "cosine_distances_duplicates = cosine_distances_matrix[duplicate_indices, :]\n",
        "\n",
        "p_at_1_accuracy_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "O_5S7yTf8KIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_at_3_accuracy_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "SwaEOv-QUfLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr_bow(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "0YHtX8DMdHEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_accuracy(cosine_distances_matrix, tech_data)"
      ],
      "metadata": {
        "id": "_GOpIvUldOsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the general dataset"
      ],
      "metadata": {
        "id": "5cYiMi9DwXt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = balanced_df[balanced_df[\"is_duplicate\"] == 1]\n",
        "all_questions = balanced_df[\"question1\"].tolist() + balanced_df[\"question2\"].tolist()"
      ],
      "metadata": {
        "id": "2KOt8UH9wYyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(all_questions)"
      ],
      "metadata": {
        "id": "Ebvr20NbxRt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1_embeddings = np.array([get_weighted_question_embedding(q, tfidf_vectorizer, tfidf, i, model)\n",
        "                                for i, q in enumerate(balanced_df[\"question1\"])])"
      ],
      "metadata": {
        "id": "17JrV1q6j2SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question2_embeddings = np.array([get_weighted_question_embedding(q, tfidf_vectorizer, tfidf, i + len(balanced_df), model)\n",
        "                                for i, q in enumerate(balanced_df[\"question2\"])])"
      ],
      "metadata": {
        "id": "wCG-TTCZkHYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1_duplicate_embeddings = question1_embeddings[duplicates.index]\n",
        "q2_duplicate_embeddings = question2_embeddings[duplicates.index]"
      ],
      "metadata": {
        "id": "KsajPEjAxgSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(q1_duplicate_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "iABdwDpYyePj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_at_1_accuracy(cosine_distances_matrix, duplicates)"
      ],
      "metadata": {
        "id": "0nziyofClROj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_at_3_accuracy(cosine_distances_matrix, duplicates)"
      ],
      "metadata": {
        "id": "-h3ZfJyKzeSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr(cosine_distances_matrix, duplicates)"
      ],
      "metadata": {
        "id": "CaePlc24znfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)\n",
        "tau_accuracy(cosine_distances_matrix, balanced_df)"
      ],
      "metadata": {
        "id": "Ms0vDrz4zx-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Our Own CBOW ##"
      ],
      "metadata": {
        "id": "HafxZ9b65ljq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "text_corpus = pd.read_csv('balanced_df.csv')\n",
        "# text_corpus = pd.read_csv('tech_data.csv')\n",
        "train_corpus = text_corpus['question1'].sample(n=10500, random_state=35).tolist()\n",
        "test_corpus = text_corpus[~text_corpus['question1'].isin(train_corpus)]"
      ],
      "metadata": {
        "id": "wijHA8zmANzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "corpus = train_corpus\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "print(\"After converting our words in the corpus into vector of integers:\")\n",
        "print(sequences)"
      ],
      "metadata": {
        "id": "5YP7MrloAOj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Define the parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_size = 400\n",
        "window_size = 5\n",
        "\n",
        "# Generate the context-target pairs\n",
        "contexts = []\n",
        "targets = []\n",
        "for sequence in sequences:\n",
        "    for i in range(window_size, len(sequence) - window_size):\n",
        "        context = sequence[i - window_size:i] + sequence[i + 1:i + window_size + 1]\n",
        "        target = sequence[i]\n",
        "        contexts.append(context)\n",
        "        targets.append(target)\n",
        "\n",
        "# Convert the contexts and targets to numpy arrays\n",
        "X = np.array(contexts)\n",
        "y = to_categorical(targets, num_classes=vocab_size)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CBOW model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=2 * window_size))\n",
        "model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
        "model.add(Dense(units=vocab_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "rlYDRhqOAtHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = model.layers[0]\n",
        "\n",
        "embedding_weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "# Function to obtain the sentence-level embedding by averaging word embeddings in the context\n",
        "def get_sentence_embedding(context):\n",
        "    word_embeddings = embedding_weights[context]\n",
        "\n",
        "    # Return the average of the embeddings for the context (you could also sum, or use other aggregations)\n",
        "    return np.mean(word_embeddings, axis=0)\n",
        "\n",
        "\n",
        "context_example = X_test[0]\n",
        "sentence_embedding = get_sentence_embedding(context_example)\n",
        "\n",
        "print(\"Sentence Embedding (Vector for this context):\")\n",
        "print(sentence_embedding)"
      ],
      "metadata": {
        "id": "Gi-KXFEbA3gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_embedding(context):\n",
        "    word_embeddings = embedding_weights[context]\n",
        "\n",
        "    return np.mean(word_embeddings, axis=0)\n",
        "\n",
        "def embed_new_sentence(new_sentence, tokenizer, model, window_size=2):\n",
        "\n",
        "    new_sequence = tokenizer.texts_to_sequences([new_sentence])[0]\n",
        "\n",
        "    if len(new_sequence) <= 2 * window_size:\n",
        "\n",
        "        return np.zeros((embedding_size,))\n",
        "\n",
        "\n",
        "    contexts = []\n",
        "    for i in range(window_size, len(new_sequence) - window_size):\n",
        "        context = new_sequence[i - window_size:i] + new_sequence[i + 1:i + window_size + 1]\n",
        "        contexts.append(context)\n",
        "\n",
        "    X_new = np.array(contexts)\n",
        "\n",
        "    embedding_layer = model.layers[0]\n",
        "    embedding_weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "\n",
        "    sentence_embeddings = np.array([get_sentence_embedding(context) for context in X_new])\n",
        "\n",
        "    final_sentence_embedding = np.mean(sentence_embeddings, axis=0)\n",
        "\n",
        "    return final_sentence_embedding"
      ],
      "metadata": {
        "id": "lqsr9WUwBCC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_cosine_similarity(embedding1, embedding2):\n",
        "    return cosine_similarity([embedding1], [embedding2])[0][0]"
      ],
      "metadata": {
        "id": "O28DV8s5BvGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keyword_rows = test_corpus\n",
        "test_corpus = pd.read_csv('tech_data.csv')\n",
        "\n",
        "\n",
        "all_questions1 = keyword_rows['question1'].tolist()\n",
        "all_questions2 = keyword_rows['question2'].tolist()\n",
        "\n",
        "embeddings_question1 = np.array([\n",
        "    embed_new_sentence(q, tokenizer, model) for q in all_questions1\n",
        "])\n",
        "\n",
        "embeddings_question2 = np.array([\n",
        "    embed_new_sentence(q, tokenizer, model) for q in all_questions2\n",
        "])\n",
        "\n",
        "cosine_similarities = np.array([\n",
        "    compute_cosine_similarity(emb1, emb2)\n",
        "    for emb1, emb2 in zip(embeddings_question1, embeddings_question2)\n",
        "])"
      ],
      "metadata": {
        "id": "jaLiOq_0BxVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max = 0\n",
        "print(\"Cosine Similarities for Question Pairs:\")\n",
        "for i, similarity in enumerate(cosine_similarities):\n",
        "\n",
        "    question1_text = all_questions1[i]\n",
        "    question2_text = all_questions2[i]\n",
        "\n",
        "    print(f\"Question 1: {question1_text}\")\n",
        "    print(f\"Question 2: {question2_text}\")\n",
        "    print(f\"Cosine Similarity: {similarity}\")\n",
        "    max +=1\n",
        "    if max == 10:\n",
        "      break"
      ],
      "metadata": {
        "id": "oVgvapgZBzVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "total_predictions = len(cosine_similarities)\n",
        "\n",
        "\n",
        "for i, similarity in enumerate(cosine_similarities):\n",
        "    is_duplicate = test_corpus.iloc[i]['is_duplicate']\n",
        "\n",
        "    if similarity > 0.8:\n",
        "        predicted_label = 1\n",
        "    else:\n",
        "        predicted_label = 0\n",
        "\n",
        "\n",
        "    if predicted_label == is_duplicate:\n",
        "        correct_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "\n",
        "print(f\"Number of correct predictions: {correct_predictions}\")\n",
        "print(f\"Total number of comparisons: {total_predictions}\")\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "349Bbt0wB1-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_matches = 0\n",
        "total_checked = 20\n",
        "\n",
        "for i in range(min(total_checked, len(cosine_similarities))):\n",
        "    is_duplicate = test_corpus.iloc[i]['is_duplicate']\n",
        "\n",
        "    question1 = all_questions1[i]\n",
        "    question2 = all_questions2[i]\n",
        "\n",
        "    emb1 = embeddings_question1[i]\n",
        "\n",
        "    similarities_with_others = np.array([compute_cosine_similarity(emb1, emb2) for emb2 in embeddings_question1 + embeddings_question2])\n",
        "\n",
        "    similarities_with_others[i] = -1\n",
        "    most_similar_index = np.argmax(similarities_with_others)\n",
        "    most_similar_similarity = similarities_with_others[most_similar_index]\n",
        "\n",
        "    if most_similar_index < len(embeddings_question1):\n",
        "        most_similar_question = all_questions1[most_similar_index]\n",
        "    else:\n",
        "        most_similar_question = all_questions2[most_similar_index - len(embeddings_question1)]\n",
        "\n",
        "    if most_similar_index == i + len(embeddings_question1):\n",
        "        correct_matches += 1\n",
        "        correct_match_status = \"Correct\"\n",
        "    else:\n",
        "        correct_match_status = \"Incorrect\"\n",
        "\n",
        "    print(f\"Question 1: {question1}\")\n",
        "    print(f\"Question 2: {question2}\")\n",
        "    print(f\"Cosine Similarity with most similar question: {most_similar_similarity:.4f}\")\n",
        "    print(f\"Most Similar Question: {most_similar_question}\")\n",
        "    print(f\"True Label (is_duplicate): {is_duplicate}\")\n",
        "    print(f\"Prediction: {correct_match_status}\\n\")"
      ],
      "metadata": {
        "id": "HLGK9-BhB46q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "## Try top 3\n",
        "cosine_distances_matrix = cosine_distances(embeddings_question1, embeddings_question2)\n",
        "top_3_matches = np.argsort(cosine_distances_matrix, axis=1)[:, :3]\n",
        "correct_matches = np.array([i in top_3_matches[i] for i in range(len(keyword_rows))])\n",
        "top_3_accuracy = np.mean(correct_matches)\n",
        "print(f\"P@3: {top_3_accuracy:.2f}\")\n",
        "\n",
        "correct_ranks = []\n",
        "for i in range(len(cosine_similarities)):\n",
        "    sorted_indices = np.argsort(cosine_similarities)\n",
        "    rank = np.where(sorted_indices == i)[0]\n",
        "    if len(rank) > 0:\n",
        "        correct_ranks.append(rank[0] + 1)\n",
        "    else:\n",
        "        correct_ranks.append(float('inf'))\n",
        "\n",
        "# P@1\n",
        "p_at_1 = np.mean([1 if rank == 1 else 0 for rank in correct_ranks])\n",
        "\n",
        "# MRR\n",
        "mrr = np.mean([1 / rank for rank in correct_ranks if rank != float('inf')])\n",
        "\n",
        "\n",
        "print(f\"P@1: {p_at_1:.2f}\")\n",
        "print(f\"MRR: {mrr:.2f}\")"
      ],
      "metadata": {
        "id": "5n3M4MCCB7Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying Binary Classification Approach -- As Is (No Fine-Tuning)"
      ],
      "metadata": {
        "id": "CU4aSr7yabq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uTHF51QraiFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionPairDataset(Dataset):\n",
        "  def __init__(self, df, tokenizer):\n",
        "    self.df = df\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    row = self.df.iloc[index]\n",
        "    question1 = row['question1']\n",
        "    question2 = row['question2']\n",
        "    label = row['is_duplicate']\n",
        "\n",
        "    inputs = self.tokenizer(\n",
        "        text=question1,\n",
        "        text_pair=question2,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\")\n",
        "\n",
        "    return {'input_ids': inputs['input_ids'].squeeze(0),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)}"
      ],
      "metadata": {
        "id": "nr5ZrDnqbSeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  true_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      logits = outputs.logits\n",
        "      preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "      predictions.extend(preds.cpu().numpy())\n",
        "      true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "  return predictions, true_labels"
      ],
      "metadata": {
        "id": "SX3Ar2E3c0kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "z-o3hSMQivoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "baseline_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2).to(device)"
      ],
      "metadata": {
        "id": "_axo9BU0dhE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For tech dataset"
      ],
      "metadata": {
        "id": "qKza3TDQdmIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = QuestionPairDataset(tech_data, tokenizer)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "baseline_predictions, baseline_true_labels = evaluate(baseline_model, test_loader)\n",
        "baseline_accuracy = accuracy_score(baseline_true_labels, baseline_predictions)\n",
        "baseline_report = classification_report(baseline_true_labels, baseline_predictions)\n",
        "\n",
        "print(f\"Baseline Test Accuracy: {baseline_accuracy}\")\n",
        "print(baseline_report)"
      ],
      "metadata": {
        "id": "RKsTvBrhdlWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For general dataset"
      ],
      "metadata": {
        "id": "rgpc9P8adc-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = QuestionPairDataset(balanced_df, tokenizer)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "baseline_predictions, baseline_true_labels = evaluate(baseline_model, test_loader)\n",
        "baseline_accuracy = accuracy_score(baseline_true_labels, baseline_predictions)\n",
        "baseline_report = classification_report(baseline_true_labels, baseline_predictions)\n",
        "\n",
        "print(f\"Baseline Test Accuracy: {baseline_accuracy}\")\n",
        "print(baseline_report)"
      ],
      "metadata": {
        "id": "IqLrJz-JcXRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying Binary Classification Approach -- With Fine-Tuning"
      ],
      "metadata": {
        "id": "gB13Tsn8buvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fined_tuned_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2).to(device)"
      ],
      "metadata": {
        "id": "fe0eiYt6fye_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(tech_data, test_size=0.3, random_state=42)\n",
        "\n",
        "train_dataset = QuestionPairDataset(train_data, tokenizer)\n",
        "test_dataset = QuestionPairDataset(test_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "o-qLV0VCgalJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(fined_tuned_model.parameters(), lr=2e-5)\n",
        "epochs = 3\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  correct_predictions = 0\n",
        "  total = 0\n",
        "  fined_tuned_model.train()\n",
        "\n",
        "  for batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    outputs = fined_tuned_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "    loss = outputs.loss\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    logits = outputs.logits\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    correct_predictions += (preds == labels).sum().item()\n",
        "    total += labels.size(0)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_losses.append(epoch_loss / len(train_loader))\n",
        "  train_accuracies.append(correct_predictions / total)\n",
        "\n",
        "  print(f\"Epoch loss: {train_losses[-1]}, Epoch accuracy: {train_accuracies[-1]}\")"
      ],
      "metadata": {
        "id": "eliJCY1UcPNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_predictions, fine_tuned_true_labels = evaluate(fined_tuned_model, test_loader)\n",
        "fine_tuned_accuracy = accuracy_score(fine_tuned_true_labels, fine_tuned_predictions)\n",
        "fine_tuned_report = classification_report(fine_tuned_true_labels, fine_tuned_predictions)\n",
        "\n",
        "print(f\"Fine-Tuned Test Accuracy: {fine_tuned_accuracy}\")\n",
        "print(fine_tuned_report)"
      ],
      "metadata": {
        "id": "Yfh8gn0Mfi6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying BERT w/ Cosine Distance -- As Is (No Fine-Tuning) ##"
      ],
      "metadata": {
        "id": "7v-9mB81SfLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Pre-trained BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "1itgZ24VSi5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "bert_model.eval()"
      ],
      "metadata": {
        "id": "Pmx4n6SPpFq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_embeddings(questions, tokenizer, model):\n",
        "  embeddings = []\n",
        "  with torch.no_grad():\n",
        "    for question in questions:\n",
        "      inputs = tokenizer(text = question,\n",
        "               truncation = True,\n",
        "               padding = True,\n",
        "               add_special_tokens = True,\n",
        "               return_tensors = \"pt\")\n",
        "\n",
        "      input_ids = inputs[\"input_ids\"]\n",
        "      attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "      input_ids = input_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      last_hidden_state = outputs[0]\n",
        "      cls_representation = last_hidden_state[:,0,:]\n",
        "      embeddings.append(cls_representation.cpu().numpy())\n",
        "\n",
        "  return np.vstack(embeddings)"
      ],
      "metadata": {
        "id": "LhFSdiJZpfHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the tech dataset"
      ],
      "metadata": {
        "id": "GSwZLjTbmI66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question1_embeddings = cls_embeddings(tech_data[\"question1\"], tokenizer, bert_model)\n",
        "question2_embeddings = cls_embeddings(tech_data[\"question2\"], tokenizer, bert_model)"
      ],
      "metadata": {
        "id": "k3bAtf-7sv0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "6ZJy2c8Vs8bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = tech_data[tech_data[\"is_duplicate\"] == 1]\n",
        "duplicate_indices = duplicates.index.tolist()\n",
        "cosine_distances_duplicates = cosine_distances_matrix[duplicate_indices, :]\n",
        "\n",
        "p_at_1_accuracy(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "DJswEsfzUfHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_at_3_accuracy(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "tbjVqzROtv92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "bmCVwZBMup2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_accuracy(cosine_distances_matrix, tech_data)"
      ],
      "metadata": {
        "id": "KNRAOlXHvQw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the general dataset"
      ],
      "metadata": {
        "id": "4KKiJaXexZmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question1_embeddings = cls_embeddings(balanced_df[\"question1\"], tokenizer, bert_model)\n",
        "question2_embeddings = cls_embeddings(balanced_df[\"question2\"], tokenizer, bert_model)"
      ],
      "metadata": {
        "id": "Otvqsd5Qxcl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "yRRXbGe7xjGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting P@1\n",
        "duplicates = balanced_df[balanced_df[\"is_duplicate\"] == 1]\n",
        "duplicate_indices = duplicates.index.tolist()\n",
        "cosine_distances_duplicates = cosine_distances_matrix[duplicate_indices, :]\n",
        "\n",
        "p_at_1_accuracy(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "quEEB_ajxnT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting P@3\n",
        "p_at_3_accuracy(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "zIzCyB9Dy3va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting MRR\n",
        "mrr(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "8miDDoV1y47U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_accuracy(cosine_distances_matrix, balanced_df)"
      ],
      "metadata": {
        "id": "kPjjzvE6y_HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying BERT w/ Cosine Distance -- With Fine-Tuning ##"
      ],
      "metadata": {
        "id": "gH62lX2dXH36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Source\n",
        "# https://huggingface.co/docs/transformers/en/tasks/masked_language_modeling\n",
        "\n",
        "class TokenizeQuestion(Dataset):\n",
        "  def __init__(self, q, tokenizer, max_length=128):\n",
        "    self.questions = q\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.questions)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    quest = self.questions[idx]\n",
        "    tokens = self.tokenizer(text = quest, truncation = True, padding= True, add_special_tokens = True, return_tensors=\"pt\")\n",
        "    return {key: val.squeeze(0) for key, val in tokens.items()}"
      ],
      "metadata": {
        "id": "KBPG-A_azmCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "V4JcEIcvKHX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)\n",
        "bert_model.eval()"
      ],
      "metadata": {
        "id": "1XYhL6J2KOT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_mlm\",\n",
        "    eval_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=False,\n",
        ")"
      ],
      "metadata": {
        "id": "xTzfl71YKTkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_embeddings(questions, tokenizer, model):\n",
        "  embeddings = []\n",
        "  with torch.no_grad():\n",
        "    for question in questions:\n",
        "      inputs = tokenizer(text = question,\n",
        "               truncation = True,\n",
        "               padding = True,\n",
        "               add_special_tokens = True,\n",
        "               return_tensors = \"pt\")\n",
        "\n",
        "      input_ids = inputs[\"input_ids\"]\n",
        "      attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "      input_ids = input_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      last_hidden_state = outputs[0]\n",
        "      cls_representation = last_hidden_state[:,0,:]\n",
        "      embeddings.append(cls_representation.cpu().numpy())\n",
        "\n",
        "  return np.vstack(embeddings)"
      ],
      "metadata": {
        "id": "eP2xbAteIrW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For tech dataset:"
      ],
      "metadata": {
        "id": "Z-ZrC14sKZA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(tech_data, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "4mHkBmg8NU7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions = train_df[\"question1\"].tolist() + train_df[\"question2\"].tolist()"
      ],
      "metadata": {
        "id": "EJFa20sMKb5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TokenizeQuestion(train_questions, tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm = True, mlm_probability = 0.15)"
      ],
      "metadata": {
        "id": "dAnq2RGHKeWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "gZ8V_QamKv-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "J0TemW24IVI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1_embeddings = cls_embeddings(test_df[\"question1\"], tokenizer, bert_model)\n",
        "question2_embeddings = cls_embeddings(test_df[\"question2\"], tokenizer, bert_model)"
      ],
      "metadata": {
        "id": "x2g4PnAsIJsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "9W3JZmNsKBG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.reset_index(drop=True)\n",
        "duplicates = test_df[test_df[\"is_duplicate\"] == 1]\n",
        "duplicate_indices = duplicates.index.tolist()\n",
        "cosine_distances_duplicates = cosine_distances_matrix[duplicate_indices, :]\n",
        "\n",
        "p_at_1_accuracy(cosine_distances_duplicates, duplicates)"
      ],
      "metadata": {
        "id": "sSeGI24oMZtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_accuracy(cosine_distances_matrix, test_df)"
      ],
      "metadata": {
        "id": "9T3lEHH5Mhc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For general dataset"
      ],
      "metadata": {
        "id": "yNrPmuraSE2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(balanced_df, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "L5R27yAQZ7qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions = train_df[\"question1\"].tolist() + train_df[\"question2\"].tolist()"
      ],
      "metadata": {
        "id": "kpuctXApZ9I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TokenizeQuestion(train_questions, tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm = True, mlm_probability = 0.15)"
      ],
      "metadata": {
        "id": "h69u3t48aAkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "qECvzxTQaDTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "hvERtTX6aGjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1_embeddings = cls_embeddings(test_df[\"question1\"], tokenizer, bert_model)\n",
        "question2_embeddings = cls_embeddings(test_df[\"question2\"], tokenizer, bert_model)"
      ],
      "metadata": {
        "id": "EqLucpVGaJaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_distances_matrix = cosine_distances(question1_embeddings, question2_embeddings)"
      ],
      "metadata": {
        "id": "womlEV36aL_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}